[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Carson McKee",
    "section": "",
    "text": "I am a third year statistics PhD candidate in the Department of Mathematics at King’s College London. My research focuses on Bayesian methods and computational statistics, including:\n\nBayesian Nonparametrics\nTime series analysis\nChange-point detection\nMonte Carlo methods\nParticle Filtering"
  },
  {
    "objectID": "seminars.html",
    "href": "seminars.html",
    "title": "KCL Junior Statistics Seminar Series",
    "section": "",
    "text": "The KCL Junior Statistics Seminar series runs bi weekly on Mondays. Below are a list of previous and upcoming talks. If you would like to contribute a talk, please contact one of the organisers at carson.mckee@kcl.ac.uk or ziyou.wang@kcl.ac.uk."
  },
  {
    "objectID": "seminars.html#fall-2024",
    "href": "seminars.html#fall-2024",
    "title": "KCL Junior Statistics Seminar Series",
    "section": "Fall 2024",
    "text": "Fall 2024\n4th Nomember 2024\nTime: TBC, Room: TBC\nTitle: Mutually Dependent Bernoulli Processes for Multivariate Change-Point Detection\nPresenter: Carson McKee (KCL)\nAbstract: Financial and economic time series exhibit sharp structural breaks, or change-points, driven by events such as recessions or financial market crashes. In the multivariate setting, these changes may occur asynchronously across series. It is often the case that the occurrence of a change-point in one series affects the probability of a subsequent change occurring in another. This is observed, for example, in financial contagion, when turmoil spreads from one country to another. A multivariate change-point prior is developed, which explicitly models this dependence using discrete time and mutually dependent point processes. Under this prior, the probability of a change-point occurring in a series at a given time is dependent on recent changes in other series. Thus, the model allows for both cross-sectional and temporal dependence in the change-point probabilities. Then, conditional on the change-point locations, the data in each segment is assumed to be independent of the data in other segments. Obtaining posterior estimates under this model is non-trivial. A blocked Gibbs sampler and a particle Gibbs sampler are developed for use in high dimensions. The model is demonstrated on simulated and real datasets and is shown to uncover latent dependencies linking change-points in different series.\n18th Nomember 2024\nTime: TBC, Room: TBC\nTitle: TBC\nPresenter: Ziyou Wang (KCL)\nAbstract: TBC"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Academic CV",
    "section": "",
    "text": "King’s College London | PhD - Statistics | Sept 2022 - Present\nUniversity of St. Andrews | MMath - Statistics (1st) | Sept 2016 - June 2020"
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "Academic CV",
    "section": "",
    "text": "King’s College London | PhD - Statistics | Sept 2022 - Present\nUniversity of St. Andrews | MMath - Statistics (1st) | Sept 2016 - June 2020"
  },
  {
    "objectID": "cv.html#experience",
    "href": "cv.html#experience",
    "title": "Academic CV",
    "section": "Experience",
    "text": "Experience\nBank of America Merrill Lynch | Software Engineer | August 2020 - September 2022\nBritish Army Reserve | Troop Leader | June 2017 - June 2020"
  },
  {
    "objectID": "cv.html#talks-and-posters",
    "href": "cv.html#talks-and-posters",
    "title": "Academic CV",
    "section": "Talks and Posters",
    "text": "Talks and Posters\n24/06/2024 (Poster) UCLA: Network Modelling of Asynchronous Change-Points in Multivariate Time Series.\n26/02/202 (Invited Talk) UCL: Network Modelling of Asynchronous Change-Points in Multivariate Time Series.\n15/12/2024 (Invited Talk) CFE CMStatistics: Mutually Dependent Bernoulli Processes for Multivariate Change-Point Detection.\n05/06/2024 (Poster) ISBA World Meeting Venice: Bayesian Nonparametric Change-Point Detection for Multivariate Time Series.\n04/06/2024 (Contributed Talk) ISBA World Meeting Venice: Bayesian Nonparametric Change-Point Detection for Multivariate Time Series.\n05/12/2023 (Poster) ISBA BNP Melbourne: Bayesian Nonparametric Change-Point Modelling for Macroeconomic Time Series."
  },
  {
    "objectID": "cv.html#funding-and-awards",
    "href": "cv.html#funding-and-awards",
    "title": "Academic CV",
    "section": "Funding and Awards",
    "text": "Funding and Awards\n\nMy PhD is funded by a 4-year studentship from the Heilbronn Institute for Mathematical Research.\n$500 travel grant to present at the 14th International Conference on Bayesian Nonparametrics (2025, UCLA).\n$500 travel grant to present at ISBA BNP (Melbourne, 2023).\nBest poster award at ISBA World Meeting (Venice, 2024)."
  },
  {
    "objectID": "cv.html#publications",
    "href": "cv.html#publications",
    "title": "Academic CV",
    "section": "Publications",
    "text": "Publications\nMcKee, C. & Kalli, M. (2025) Network Modelling of Asynchronous Change-Points in Multivariate Time Series. (In review, available on Arxiv.)"
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "BayesGLM\nBayesGLM is a Python package for fitting Generalised Linear Models within a Bayesian framework. The package supports a wide range of prior distributions. Models are fitted by using an adaptive Metropolis Hastings algorithm. The underlying mathematics is written in C++ for speed and interfaces with Python using Cython. The model fitting is done via a central ‘glm’ object, similar in functionality to that found in the R language. Source is available at bayesglm.\nExample snippets for fitting a Bayesian logistic regression using BayesGLM are given below.\nimport pandas\nfrom bayesglm.bglm import glm\nfrom bayesglm.distributions import Binomial, Normal, Uninformed\n\ndata = pandas.read_excel(\"data/bernoulli_data.xls\", header=None)\ndata.columns = [\"y\", \"x1\", \"x2\", \"x3\"]\n\npriors = {\n    \"Intercept\" : Uninformed(),\n    \"x1\"        : Normal(mu=0, sigma=3),\n    \"x2\"        : Normal(mu=0, sigma=3),\n    \"x3\"        : Normal(mu=0, sigma=3)\n}\n\nmodel = glm(formula=\"y ~ x1 + x2 + x3\",\n            priors=priors,\n            family=Binomial(link='logit'),\n            data=data)\nWe fit the model via MCMC sampling (adaptive Metropolis-Hastings).\nmodel.fit(chain_length=30000, burn_in=5000)\n[=====================================================================&gt;] 30000/30000 (2 seconds)\nWe can then view a summary of the posterior distribution.\nmodel.summary()\n                                Bayesian GLM Summary\n------------------------------------------------------------------------------------\nDIC: 72.4154        | Chain iters : 30000  | Formula :   y ~ .          \nN  : 76             | Burn-in     : 5000   | Family  :   binomial(link=logit)\n------------------------------------------------------------------------------------\nNode       Prior        Mean        s.d.      [2.5%        97.5%]       Acc. Rate\n------------------------------------------------------------------------------------\nIntercept  uninformed   1.747       0.360     1.077        2.496        0.284       \nx1         normal       0.782       0.486     -0.127       1.764        0.301       \nx2         normal       0.606       0.422     -0.215       1.451        0.260       \nx3         normal       -0.406      0.390     -1.189       0.322        0.259       \n------------------------------------------------------------------------------------\nVarious plots can also be produced. For example, we may view the sampled MCMC chains using:\nmodel.plot_chain_trace(burn_in=False)\nplt.show()\nplt.close()\n\n\n\nNGlm\nAn R library for fitting Bayesian linear models using Normal-Gamma shrinkage priors (Griffin and Brown, 2010). Such priors are appropriate when we have many predictors but relatively few data points. Posterior inference is performed using the blocked Gibbs sampler of Griffin and Brown (2010). The numerical code is written in C++ for efficiency and interfaces with R using the Rcpp API. This library is available at NGlm. Example usage of the R package is given below.\nlibrary(NGlm)\n\n# generate dummy data\nset.seed(1234)\np &lt;- 100\nn &lt;- 75\nX &lt;- matrix(rnorm(p*n, 0, 1), nrow=n, ncol=p)\nbeta &lt;- rep(0, p)\nbeta[1:5] &lt;- 5\ny &lt;- X%*%beta + rnorm(n, 0, 1)\n\n# fit the model\nmod &lt;- NG(y, X, verbose=FALSE, n_samples=10000, n_thin=1)\n\n# inspect the beta 1 chain\nplot(mod$samples[2000:10000, 'beta_1'], type='l')\n\n# geneate posterior summary estimates\nsummary(mod, burnin=2000)\nProduces the output:\nCall:\nNG(y = y, X = X, verbose = FALSE)\nn =  75 \np =  100 \n\nMCMC Samples: 10000  Burn-in: 2000 \n\nCoefficients (non-zero only):\n            mean     2.5%    97.5%\nalpha   1.839836 1.600198 2.086501\nbeta_1  4.916641 4.685911 5.152642\nbeta_10 5.090981 4.865482 5.313934\nbeta_20 4.970170 4.666417 5.281846\nbeta_30 4.861412 4.632176 5.087879\nbeta_40 5.110184 4.879636 5.340332\n\nErrors Standard Deviation:\n     mean      2.5%     97.5% \n0.8611414 0.6948363 1.0581903 \n\nShrinkage Parameters:\n             mean        2.5%      97.5%\nlambda 0.02819610 0.015775557 0.04301182\ngamma  0.04357078 0.007551935 0.11947228"
  }
]